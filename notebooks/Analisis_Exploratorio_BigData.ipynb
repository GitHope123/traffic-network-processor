{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Tráfico de Red\n",
    "\n",
    "Análisis completo de patrones de tráfico de red, detección de anomalías y caracterización de ataques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración e Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "# Inicialización de Spark con configuración optimizada\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NetworkTrafficAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: 2830736 filas x 79 columnas\n",
      "\n",
      "Primeras 5 columnas: ['Destination_Port', 'Flow_Duration', 'Total_Fwd_Packets', 'Total_Backward_Packets', 'Total_Length_of_Fwd_Packets']\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "input_path = '../data/raw/network_data.csv'\n",
    "df_raw = spark.read.option('header', 'true').option('inferSchema', 'true').csv(input_path)\n",
    "\n",
    "# Limpieza de nombres de columnas\n",
    "df = df_raw.toDF(*[c.strip().replace(' ', '_').replace('/', '_').replace('.', '_') for c in df_raw.columns])\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "print(f\"\\nPrimeras 5 columnas: {df.columns[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset procesado y almacenado en cache\n"
     ]
    }
   ],
   "source": [
    "# Mapeo y creación de variables derivadas\n",
    "column_mapping = {\n",
    "    'Destination_Port': 'destination_port',\n",
    "    'Flow_Duration': 'flow_duration',\n",
    "    'Total_Fwd_Packets': 'total_fwd_packets',\n",
    "    'Total_Backward_Packets': 'total_backward_packets',\n",
    "    'Total_Length_of_Fwd_Packets': 'total_fwd_bytes',\n",
    "    'Total_Length_of_Bwd_Packets': 'total_bwd_bytes',\n",
    "    'Label': 'attack_type'\n",
    "}\n",
    "\n",
    "# Aplicar renombrado\n",
    "for old_name, new_name in column_mapping.items():\n",
    "    if old_name in df.columns:\n",
    "        df = df.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "# Variables derivadas\n",
    "df = df.withColumn('total_packets', \n",
    "                   coalesce(col('total_fwd_packets'), lit(0)) + coalesce(col('total_backward_packets'), lit(0)))\n",
    "df = df.withColumn('total_bytes', \n",
    "                   coalesce(col('total_fwd_bytes'), lit(0)) + coalesce(col('total_bwd_bytes'), lit(0)))\n",
    "df = df.withColumn('packet_size_avg', \n",
    "                   when(col('total_packets') > 0, col('total_bytes') / col('total_packets')).otherwise(0))\n",
    "df = df.withColumn('bytes_per_second', \n",
    "                   when(col('flow_duration') > 0, col('total_bytes') * 1000000.0 / col('flow_duration')).otherwise(0))\n",
    "\n",
    "# Persistir en memoria\n",
    "df = df.repartition(16).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "print(\"Dataset procesado y almacenado en cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis Descriptivo General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTADÍSTICAS GENERALES ===\n",
      "Total de registros: 2,830,736\n",
      "Total de columnas: 83\n",
      "\n",
      "=== ESTADÍSTICAS DESCRIPTIVAS ===\n",
      "+-------+------------------+------------------+--------------------+------------------+-------------------+\n",
      "|summary|     total_packets|       total_bytes|       flow_duration|   packet_size_avg|   bytes_per_second|\n",
      "+-------+------------------+------------------+--------------------+------------------+-------------------+\n",
      "|  count|           2830736|           2830736|             2830736|           2830736|            2830736|\n",
      "|   mean|19.754900492310128|16711.972962155425|1.4785620264671803E7|184.72267293328247| 1490183.0986010963|\n",
      "| stddev|1746.6651284911054| 2266645.477299444| 3.365367906074919E7| 331.1007762091756|2.590706378761566E7|\n",
      "|    min|                 2|                 0|                 -13|               0.0|                0.0|\n",
      "|    max|            511681|         656776408|           119999998|3893.3333333333335|            2.071E9|\n",
      "+-------+------------------+------------------+--------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estadísticas generales\n",
    "print(\"=== ESTADÍSTICAS GENERALES ===\")\n",
    "print(f\"Total de registros: {df.count():,}\")\n",
    "print(f\"Total de columnas: {len(df.columns)}\")\n",
    "\n",
    "# Estadísticas descriptivas de variables clave\n",
    "numeric_columns = ['total_packets', 'total_bytes', 'flow_duration', 'packet_size_avg', 'bytes_per_second']\n",
    "print(\"\\n=== ESTADÍSTICAS DESCRIPTIVAS ===\")\n",
    "df.select(numeric_columns).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis por Puertos y Protocolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISIS POR CATEGORÍAS DE PUERTOS ===\n",
      "+---------------+-----------+-------------+-----------+------------------+\n",
      "|  port_category|total_flows|total_packets|total_bytes|   avg_packet_size|\n",
      "+---------------+-----------+-------------+-----------+------------------+\n",
      "|            DNS|     957971|      3515828|  267505873| 77.97614235002439|\n",
      "|           HTTP|     618934|     30032606|33925655371| 470.2674314806422|\n",
      "|          HTTPS|     505710|     18532141|12453534233|235.85317539405386|\n",
      "|USER_REGISTERED|     319256|      1013618|  117143517| 26.62045525207347|\n",
      "|DYNAMIC_PRIVATE|     309238|       998673|  275562682| 72.99750338632634|\n",
      "|   SYSTEM_OTHER|     100992|      1054143|  204489336|  58.3908678083341|\n",
      "|            SSH|      16939|       594313|   63292483|52.840954298968185|\n",
      "|        UNKNOWN|       1696|       179586|          0|               0.0|\n",
      "+---------------+-----------+-------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorización de puertos\n",
    "df = df.withColumn('port_category', \n",
    "    when(col('destination_port') == 80, 'HTTP')\n",
    "    .when(col('destination_port') == 443, 'HTTPS')\n",
    "    .when(col('destination_port') == 22, 'SSH')\n",
    "    .when(col('destination_port') == 53, 'DNS')\n",
    "    .when((col('destination_port') >= 1) & (col('destination_port') <= 1023), 'SYSTEM_OTHER')\n",
    "    .when((col('destination_port') >= 1024) & (col('destination_port') <= 49151), 'USER_REGISTERED')\n",
    "    .when(col('destination_port') >= 49152, 'DYNAMIC_PRIVATE')\n",
    "    .otherwise('UNKNOWN'))\n",
    "\n",
    "print(\"=== ANÁLISIS POR CATEGORÍAS DE PUERTOS ===\")\n",
    "port_analysis = df.groupBy('port_category').agg(\n",
    "    count('*').alias('total_flows'),\n",
    "    sum('total_packets').alias('total_packets'),\n",
    "    sum('total_bytes').alias('total_bytes'),\n",
    "    avg('packet_size_avg').alias('avg_packet_size')\n",
    ").orderBy(desc('total_flows'))\n",
    "\n",
    "port_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP 20 PUERTOS MÁS UTILIZADOS ===\n",
      "+----------------+----------+-------------+--------------------+\n",
      "|destination_port|flow_count|total_packets|           avg_speed|\n",
      "+----------------+----------+-------------+--------------------+\n",
      "|              53|    957971|      3515828|  503632.01583282725|\n",
      "|              80|    618934|     30032606|  235978.60993893622|\n",
      "|             443|    505710|     18532141|   300309.0718942788|\n",
      "|             123|     23880|        73059|  143598.81054866142|\n",
      "|              22|     16939|       594313|   54058.10868003305|\n",
      "|              21|     13522|       228015|   569362.6515374259|\n",
      "|             137|      7917|       111341| 2.316246182393559E7|\n",
      "|             389|      6405|       133717|   1499237.405293274|\n",
      "|              88|      5579|        38571|  3042668.6218578396|\n",
      "|             465|      3817|        77970|  1645082.2491154023|\n",
      "|             139|      2881|        67541|   87313.05365284432|\n",
      "|            8080|      2777|        24216|   79036.18664442482|\n",
      "|            3268|      2566|        94169|   355379.4278211215|\n",
      "|             445|      2111|        88888|   65759.08517089351|\n",
      "|               0|      1696|       179586|                 0.0|\n",
      "|             138|      1612|        25066|1.0883078708778009E8|\n",
      "|             135|      1412|        12701|   276789.1503126433|\n",
      "|           49666|       786|        13028|   469686.0410692614|\n",
      "|            5353|       697|        24592| 3.380097634466713E7|\n",
      "|            5355|       386|         9205|   4561859.505661809|\n",
      "+----------------+----------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 20 puertos más utilizados\n",
    "print(\"=== TOP 20 PUERTOS MÁS UTILIZADOS ===\")\n",
    "top_ports = df.groupBy('destination_port').agg(\n",
    "    count('*').alias('flow_count'),\n",
    "    sum('total_packets').alias('total_packets'),\n",
    "    avg('bytes_per_second').alias('avg_speed')\n",
    ").orderBy(desc('flow_count')).limit(20)\n",
    "\n",
    "top_ports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de Patrones de Tráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PATRONES DE COMUNICACIÓN ===\n",
      "+---------------------+----------+------------------+-----------------+\n",
      "|communication_pattern|flow_count|       avg_packets|        avg_speed|\n",
      "+---------------------+----------+------------------+-----------------+\n",
      "|        BIDIRECTIONAL|   2377219|22.910163935253756|342215.6086347985|\n",
      "|   UNIDIRECTIONAL_FWD|    453517|3.2158243241157445|7507532.235524234|\n",
      "+---------------------+----------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Patrones de comunicación\n",
    "df = df.withColumn('communication_pattern',\n",
    "    when((col('total_fwd_packets') > 0) & (col('total_backward_packets') == 0), 'UNIDIRECTIONAL_FWD')\n",
    "    .when((col('total_fwd_packets') == 0) & (col('total_backward_packets') > 0), 'UNIDIRECTIONAL_BWD')\n",
    "    .when((col('total_fwd_packets') > 0) & (col('total_backward_packets') > 0), 'BIDIRECTIONAL')\n",
    "    .otherwise('NO_PACKETS'))\n",
    "\n",
    "print(\"=== PATRONES DE COMUNICACIÓN ===\")\n",
    "communication_stats = df.groupBy('communication_pattern').agg(\n",
    "    count('*').alias('flow_count'),\n",
    "    avg('total_packets').alias('avg_packets'),\n",
    "    avg('bytes_per_second').alias('avg_speed')\n",
    ").orderBy(desc('flow_count'))\n",
    "\n",
    "communication_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUCIÓN DE VELOCIDADES ===\n",
      "+--------------+-------+\n",
      "|speed_category|  count|\n",
      "+--------------+-------+\n",
      "|   MEDIUM_KB/s|1342880|\n",
      "|       LOW_B/s|1090200|\n",
      "|     HIGH_MB/s| 350612|\n",
      "|VERY_HIGH_MB/s|  47044|\n",
      "+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Análisis de velocidades\n",
    "df = df.withColumn('speed_category',\n",
    "    when(col('bytes_per_second') < 1024, 'LOW_B/s')\n",
    "    .when((col('bytes_per_second') >= 1024) & (col('bytes_per_second') < 1024*1024), 'MEDIUM_KB/s')\n",
    "    .when((col('bytes_per_second') >= 1024*1024) & (col('bytes_per_second') < 1024*1024*10), 'HIGH_MB/s')\n",
    "    .when(col('bytes_per_second') >= 1024*1024*10, 'VERY_HIGH_MB/s')\n",
    "    .otherwise('NO_DATA'))\n",
    "\n",
    "print(\"=== DISTRIBUCIÓN DE VELOCIDADES ===\")\n",
    "speed_distribution = df.groupBy('speed_category').count().orderBy(desc('count'))\n",
    "speed_distribution.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis de Seguridad y Anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UMBRALES DE ANOMALÍAS (95º PERCENTIL) ===\n",
      "Paquetes: 35\n",
      "Bytes: 11977\n",
      "Duración: 99726677 μs\n",
      "Velocidad: 2115183 B/s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "quantiles = df.approxQuantile(\n",
    "    ['total_packets', 'total_bytes', 'flow_duration', 'bytes_per_second'],\n",
    "    [0.95],\n",
    "    0.01\n",
    ")\n",
    "\n",
    "# extraer los valores del percentil 95 para cada métrica\n",
    "thresholds = [q[0] if q else 0 for q in quantiles]\n",
    "\n",
    "print(\"=== UMBRALES DE ANOMALÍAS (95º PERCENTIL) ===\")\n",
    "print(f\"Paquetes: {thresholds[0]:.0f}\")\n",
    "print(f\"Bytes: {thresholds[1]:.0f}\")\n",
    "print(f\"Duración: {thresholds[2]:.0f} μs\")\n",
    "print(f\"Velocidad: {thresholds[3]:.0f} B/s\")\n",
    "\n",
    "# Crear flags de anomalías (1 si supera el umbral)\n",
    "df = df.withColumn('anomaly_score', \n",
    "    (col('total_packets') > thresholds[0]).cast('int') + \n",
    "    (col('total_bytes') > thresholds[1]).cast('int') + \n",
    "    (col('flow_duration') > thresholds[2]).cast('int') + \n",
    "    (col('bytes_per_second') > thresholds[3]).cast('int')\n",
    ")\n",
    "\n",
    "# Clasificar el nivel de riesgo en función del score\n",
    "df = df.withColumn('risk_level',\n",
    "    when(col('anomaly_score') == 0, 'LOW')\n",
    "    .when(col('anomaly_score') == 1, 'MEDIUM')\n",
    "    .when(col('anomaly_score') == 2, 'HIGH')\n",
    "    .when(col('anomaly_score') >= 3, 'CRITICAL')\n",
    "    .otherwise('UNKNOWN')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUCIÓN DE NIVELES DE RIESGO ===\n",
      "+----------+----------+------------------+\n",
      "|risk_level|flow_count|        percentage|\n",
      "+----------+----------+------------------+\n",
      "|       LOW|   2398000| 84.71295097812018|\n",
      "|    MEDIUM|    292399| 10.32943375857021|\n",
      "|      HIGH|     98808|3.4905409759158044|\n",
      "|  CRITICAL|     41529|1.4670742873938085|\n",
      "+----------+----------+------------------+\n",
      "\n",
      "\n",
      "=== ANOMALÍAS POR CATEGORÍA DE PUERTO ===\n",
      "+---------------+-------------+------------------+\n",
      "|  port_category|anomaly_count|         avg_score|\n",
      "+---------------+-------------+------------------+\n",
      "|          HTTPS|       101054| 2.329655431749362|\n",
      "|           HTTP|        33526|2.2170255920777904|\n",
      "|USER_REGISTERED|         1702|2.1668625146886016|\n",
      "|   SYSTEM_OTHER|         1486|2.4246298788694483|\n",
      "|DYNAMIC_PRIVATE|         1396|2.0458452722063036|\n",
      "|        UNKNOWN|         1173|               2.0|\n",
      "+---------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribución de niveles de riesgo\n",
    "print(\"=== DISTRIBUCIÓN DE NIVELES DE RIESGO ===\")\n",
    "risk_distribution = df.groupBy('risk_level').agg(\n",
    "    count('*').alias('flow_count'),\n",
    "    (count('*') * 100.0 / df.count()).alias('percentage')\n",
    ").orderBy(desc('flow_count'))\n",
    "\n",
    "risk_distribution.show()\n",
    "\n",
    "# Anomalías por categoría de puerto\n",
    "print(\"\\n=== ANOMALÍAS POR CATEGORÍA DE PUERTO ===\")\n",
    "anomalies_by_port = df.filter(col('risk_level').isin(['HIGH', 'CRITICAL'])).groupBy('port_category').agg(\n",
    "    count('*').alias('anomaly_count'),\n",
    "    avg('anomaly_score').alias('avg_score')\n",
    ").orderBy(desc('anomaly_count'))\n",
    "\n",
    "anomalies_by_port.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis por Tipos de Ataque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUCIÓN DE TIPOS DE ATAQUE ===\n",
      "+--------------------+----------+--------------------+\n",
      "|         attack_type|flow_count|          percentage|\n",
      "+--------------------+----------+--------------------+\n",
      "|              BENIGN|   2273090|   80.30031765590292|\n",
      "|            DoS Hulk|    231073|   8.163000717834514|\n",
      "|            PortScan|    158930|   5.614440908654145|\n",
      "|                DDoS|    128027|   4.522746027888154|\n",
      "|       DoS GoldenEye|     10293|  0.3636156815753924|\n",
      "|         FTP-Patator|      7938|  0.2804217701686063|\n",
      "|         SSH-Patator|      5897| 0.20832038028272507|\n",
      "|       DoS slowloris|      5796| 0.20475240361517288|\n",
      "|    DoS Slowhttptest|      5499| 0.19426043262246992|\n",
      "|                 Bot|      1966| 0.06945190226146133|\n",
      "|Web Attack � Brut...|      1507|0.053237038000011304|\n",
      "|    Web Attack � XSS|       652|0.023032879081624002|\n",
      "|        Infiltration|        36|0.001271754059721...|\n",
      "|Web Attack � Sql ...|        21|7.418565348375829E-4|\n",
      "|          Heartbleed|        11|3.885915182482577E-4|\n",
      "+--------------------+----------+--------------------+\n",
      "\n",
      "\n",
      "=== CARACTERÍSTICAS POR TIPO DE ATAQUE ===\n",
      "+--------------------------+------------------+------------------+--------------------+---------------------+\n",
      "|attack_type               |avg_packets       |avg_bytes         |avg_speed           |avg_anomaly_score    |\n",
      "+--------------------------+------------------+------------------+--------------------+---------------------+\n",
      "|BENIGN                    |22.79278207198131 |19484.28741272893 |1778428.5048710948  |0.2337364556616764   |\n",
      "|Bot                       |6.53763987792472  |2709.2487283825026|305537.09537503315  |0.07884028484231943  |\n",
      "|DDoS                      |7.72826044506237  |7405.5435962726615|61118.598533897166  |0.014395400970107868 |\n",
      "|DoS GoldenEye             |9.618478577674148 |6979.747109686195 |688.2390583497232   |0.45487224327212666  |\n",
      "|DoS Hulk                  |9.485344458244796 |8052.049863030298 |29281.293420180697  |0.28880050893007836  |\n",
      "|DoS Slowhttptest          |6.705582833242408 |614.9392616839425 |2.1638744868867196E7|0.2773231496635752   |\n",
      "|DoS slowloris             |7.992926155969634 |831.277950310559  |43921.22344663289   |0.5                  |\n",
      "|FTP-Patator               |13.305366591080876|153.93890148652054|799162.4519491106   |0.1452506928697405   |\n",
      "|Heartbleed                |4480.909090909091 |7288870.363636363 |65902.80217228319   |2.909090909090909    |\n",
      "|Infiltration              |1659.8333333333333|381739.44444444444|20188.219029998847  |1.6388888888888888   |\n",
      "|PortScan                  |2.0225382243755115|13.32703706034103 |220185.05006460584  |0.0071100484490027056|\n",
      "|SSH-Patator               |27.65728336442259 |2391.1412582669154|439.8181214060331   |0.4990673223673054   |\n",
      "|Web Attack � Brute Force  |18.428002654280025|5596.239548772395 |179.28074241557647  |0.09887193098871931  |\n",
      "|Web Attack � Sql Injection|5.714285714285714 |1602.2857142857142|318.7348374927759   |0.0                  |\n",
      "|Web Attack � XSS          |11.476993865030675|5716.634969325153 |103.34657533262741  |0.05214723926380368  |\n",
      "+--------------------------+------------------+------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribución de tipos de ataque\n",
    "print(\"=== DISTRIBUCIÓN DE TIPOS DE ATAQUE ===\")\n",
    "attack_distribution = df.groupBy('attack_type').agg(\n",
    "    count('*').alias('flow_count'),\n",
    "    (count('*') * 100.0 / df.count()).alias('percentage')\n",
    ").orderBy(desc('flow_count'))\n",
    "\n",
    "attack_distribution.show()\n",
    "\n",
    "# Características por tipo de ataque\n",
    "print(\"\\n=== CARACTERÍSTICAS POR TIPO DE ATAQUE ===\")\n",
    "attack_characteristics = df.groupBy('attack_type').agg(\n",
    "    avg('total_packets').alias('avg_packets'),\n",
    "    avg('total_bytes').alias('avg_bytes'),\n",
    "    avg('bytes_per_second').alias('avg_speed'),\n",
    "    avg('anomaly_score').alias('avg_anomaly_score')\n",
    ").orderBy('attack_type')\n",
    "\n",
    "attack_characteristics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis de Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISIS DE CORRELACIONES ===\n",
      "\n",
      "Correlaciones fuertes (|r| > 0.7):\n",
      "  total_packets <-> total_bytes: 0.996\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import builtins  # Para usar el abs de Python de forma segura\n",
    "\n",
    "# Análisis de correlaciones entre variables numéricas\n",
    "print(\"=== ANÁLISIS DE CORRELACIONES ===\")\n",
    "\n",
    "correlation_vars = ['total_packets', 'total_bytes', 'flow_duration', 'packet_size_avg', 'bytes_per_second']\n",
    "\n",
    "# Filtrar datos válidos para correlación\n",
    "df_corr = df.select(correlation_vars).na.drop()\n",
    "\n",
    "# Ensamblar vector para correlación\n",
    "assembler = VectorAssembler(inputCols=correlation_vars, outputCol=\"features\")\n",
    "df_vector = assembler.transform(df_corr).select(\"features\")\n",
    "\n",
    "# Calcular matriz de correlación\n",
    "correlation_matrix = Correlation.corr(df_vector, \"features\").head()[0]\n",
    "\n",
    "# Convertir a array NumPy\n",
    "correlation_array = correlation_matrix.toArray()\n",
    "\n",
    "print(\"\\nCorrelaciones fuertes (|r| > 0.7):\")\n",
    "for i in range(len(correlation_vars)):\n",
    "    for j in range(i + 1, len(correlation_vars)):\n",
    "        corr_val = correlation_array[i][j]\n",
    "        if builtins.abs(corr_val) > 0.7:\n",
    "            print(f\"  {correlation_vars[i]} <-> {correlation_vars[j]}: {corr_val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Análisis Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUCIÓN TEMPORAL ===\n",
      "+-----------------+----------+-----------------+------------------+\n",
      "|duration_category|flow_count|      avg_packets|         avg_speed|\n",
      "+-----------------+----------+-----------------+------------------+\n",
      "|          INSTANT|   2043034|4.516461791629508| 2064068.827264687|\n",
      "|            SHORT|    279831|15.63239598186048| 2812.039330256801|\n",
      "|           MEDIUM|    111888|50.49895431145431|1928.0807170125856|\n",
      "|             LONG|    395983| 92.6023768697141| 882.6805360307583|\n",
      "+-----------------+----------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Análisis temporal basado en duración\n",
    "df = df.withColumn('duration_seconds', col('flow_duration') / 1000000.0)\n",
    "df = df.withColumn('duration_category',\n",
    "    when(col('duration_seconds') < 1, 'INSTANT')\n",
    "    .when((col('duration_seconds') >= 1) & (col('duration_seconds') < 10), 'SHORT')\n",
    "    .when((col('duration_seconds') >= 10) & (col('duration_seconds') < 60), 'MEDIUM')\n",
    "    .when((col('duration_seconds') >= 60) & (col('duration_seconds') < 300), 'LONG')\n",
    "    .when(col('duration_seconds') >= 300, 'VERY_LONG')\n",
    "    .otherwise('UNKNOWN'))\n",
    "\n",
    "print(\"=== DISTRIBUCIÓN TEMPORAL ===\")\n",
    "temporal_distribution = df.groupBy('duration_category').agg(\n",
    "    count('*').alias('flow_count'),\n",
    "    avg('total_packets').alias('avg_packets'),\n",
    "    avg('bytes_per_second').alias('avg_speed')\n",
    ").orderBy(\n",
    "    when(col('duration_category') == 'INSTANT', 1)\n",
    "    .when(col('duration_category') == 'SHORT', 2)\n",
    "    .when(col('duration_category') == 'MEDIUM', 3)\n",
    "    .when(col('duration_category') == 'LONG', 4)\n",
    "    .when(col('duration_category') == 'VERY_LONG', 5)\n",
    "    .otherwise(6)\n",
    ")\n",
    "\n",
    "temporal_distribution.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumen Ejecutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMEN EJECUTIVO ===\n",
      "\n",
      "📊 MÉTRICAS GENERALES:\n",
      "  • Total de flujos: 2,830,736\n",
      "  • Total de paquetes: 55,920,908\n",
      "  • Volumen total: 44.06 GB\n",
      "\n",
      "🔒 DISTRIBUCIÓN DE SEGURIDAD:\n",
      "  • Tráfico benigno: 2,273,090 (80.3%)\n",
      "  • Tráfico malicioso: 557,646 (19.7%)\n",
      "\n",
      "⚠️ RIESGOS IDENTIFICADOS:\n",
      "  • Flujos de alto riesgo: 140,337 (4.96%)\n",
      "\n",
      "🌐 TOP 3 CATEGORÍAS DE PUERTOS:\n",
      "  1. DNS: 957,971 flujos\n",
      "  2. HTTP: 618,934 flujos\n",
      "  3. HTTPS: 505,710 flujos\n"
     ]
    }
   ],
   "source": [
    "# Generar resumen ejecutivo\n",
    "print(\"=== RESUMEN EJECUTIVO ===\")\n",
    "\n",
    "# Métricas generales\n",
    "total_flows = df.count()\n",
    "total_packets_sum = df.agg(sum('total_packets')).collect()[0][0]\n",
    "total_bytes_sum = df.agg(sum('total_bytes')).collect()[0][0]\n",
    "\n",
    "print(f\"\\n📊 MÉTRICAS GENERALES:\")\n",
    "print(f\"  • Total de flujos: {total_flows:,}\")\n",
    "print(f\"  • Total de paquetes: {total_packets_sum:,}\")\n",
    "print(f\"  • Volumen total: {total_bytes_sum/1024/1024/1024:.2f} GB\")\n",
    "\n",
    "# Distribución de seguridad\n",
    "benign_count = df.filter(col('attack_type') == 'BENIGN').count()\n",
    "malicious_count = total_flows - benign_count\n",
    "malicious_percentage = (malicious_count / total_flows) * 100\n",
    "\n",
    "print(f\"\\n🔒 DISTRIBUCIÓN DE SEGURIDAD:\")\n",
    "print(f\"  • Tráfico benigno: {benign_count:,} ({100-malicious_percentage:.1f}%)\")\n",
    "print(f\"  • Tráfico malicioso: {malicious_count:,} ({malicious_percentage:.1f}%)\")\n",
    "\n",
    "# Riesgos identificados\n",
    "high_risk_count = df.filter(col('risk_level').isin(['HIGH', 'CRITICAL'])).count()\n",
    "risk_percentage = (high_risk_count / total_flows) * 100\n",
    "\n",
    "print(f\"\\n⚠️ RIESGOS IDENTIFICADOS:\")\n",
    "print(f\"  • Flujos de alto riesgo: {high_risk_count:,} ({risk_percentage:.2f}%)\")\n",
    "\n",
    "# Top protocolos\n",
    "top_3_ports = df.groupBy('port_category').count().orderBy(desc('count')).limit(3).collect()\n",
    "print(f\"\\n🌐 TOP 3 CATEGORÍAS DE PUERTOS:\")\n",
    "for i, row in enumerate(top_3_ports, 1):\n",
    "    print(f\"  {i}. {row['port_category']}: {row['count']:,} flujos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Preparación para Exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final preparado con 14 columnas\n",
      "Total de registros para exportación: 2,830,736\n",
      "+-------------+--------------+----------------------+\n",
      "|total_records|unique_attacks|unique_port_categories|\n",
      "+-------------+--------------+----------------------+\n",
      "|      2830736|            15|                     8|\n",
      "+-------------+--------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparar dataset final para BI\n",
    "bi_columns = [\n",
    "    'destination_port', 'port_category', 'total_packets', 'total_bytes', \n",
    "    'flow_duration', 'packet_size_avg', 'bytes_per_second',\n",
    "    'communication_pattern', 'speed_category', 'duration_category',\n",
    "    'anomaly_score', 'risk_level', 'attack_type'\n",
    "]\n",
    "\n",
    "df_final = df.select(bi_columns)\n",
    "df_final = df_final.withColumn('analysis_timestamp', current_timestamp())\n",
    "\n",
    "print(f\"Dataset final preparado con {len(bi_columns) + 1} columnas\")\n",
    "print(f\"Total de registros para exportación: {df_final.count():,}\")\n",
    "\n",
    "# Estadísticas finales\n",
    "df_final.select(\n",
    "    count('*').alias('total_records'),\n",
    "    countDistinct('attack_type').alias('unique_attacks'),\n",
    "    countDistinct('port_category').alias('unique_port_categories')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesión Spark finalizada\n"
     ]
    }
   ],
   "source": [
    "# Finalizar sesión Spark\n",
    "spark.stop()\n",
    "print(\"Sesión Spark finalizada\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
